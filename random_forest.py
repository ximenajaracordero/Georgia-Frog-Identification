# -*- coding: utf-8 -*-
"""Random_Forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V4iojSnPmDSlHJq3vkXGLj5CNXvwnuNc
"""

# 1) Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# 2) Point to the 'data' folder within your project structure
# Adjust the path below to match your specific folder structure in Google Drive
DATA_DIR = "/content/drive/MyDrive/Data Science Capstone/CODE GA Frog ID/data/processed"

import os, glob

# üîπ Recursive search: include all files and subfolders within the data directory
audio_files = glob.glob(os.path.join(DATA_DIR, "**", "*.wav"), recursive=True) \
            + glob.glob(os.path.join(DATA_DIR, "**", "*.mp3"), recursive=True) \
            + glob.glob(os.path.join(DATA_DIR, "**", "*.csv"), recursive=True)


print("Found files in data directory:", len(audio_files))

from google.colab import userdata
import os

# Retrieve API key from Colab Secrets
wandb_key = userdata.get('WANDB_API_KEY')

if wandb_key:
    os.environ["WANDB_API_KEY"] = wandb_key
    print("‚úÖ W&B API key loaded from Colab Secrets.")
else:
    print("‚ùå W&B key not found in Colab Secrets. Please add WANDB_API_KEY there.")

# @title 3.1: Load Aggregated Features
import pandas as pd
import os

# Define the path to the aggregated features file
FEATURES_FILE = "/content/drive/MyDrive/Data Science Capstone/CODE GA Frog ID/data/features_aggregated.csv"

# Load the aggregated features into a DataFrame
try:
    qdf = pd.read_csv(FEATURES_FILE)
    print(f"‚úÖ Loaded features from {FEATURES_FILE}")
    print("Extracted features shape:", qdf.shape)
    display(qdf.head())
except FileNotFoundError:
    print(f"‚ùå Error: {FEATURES_FILE} not found. Please make sure the file exists in the specified directory.")
except Exception as e:
    print(f"‚ùå An error occurred while loading the features file: {e}")

# --- 3.1 Build feature matrix and labels ---
import numpy as np

# assuming qdf is your processed-only DataFrame
qdf = qdf.dropna()


#X = qdf[["centroid_mean", "bandwidth_mean", "rolloff_mean", "centroid_std"]].values


# Expanded feature set: spectral + MFCCs
feature_cols = [
    "centroid_mean", "centroid_std",
    "bandwidth_mean", "bandwidth_std",
    "rolloff_mean", "rolloff_std",
] + [f"mfcc{i}_mean" for i in range(1, 14)] + [f"mfcc{i}_std" for i in range(1, 14)]

X = qdf[feature_cols].dropna().values


y = qdf["species"].values

print("‚úÖ Feature matrix shape:", X.shape)
print("‚úÖ Labels shape:", y.shape)

import wandb
wandb.login(key=os.environ["WANDB_API_KEY"])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# 
# wandb.init(
#     project="georgia-frog-classification",
#     name="rf-baseline",
#     config={
#         "model": "RandomForestClassifier",
#         "n_estimators": 200,
#         "features": ["centroid_mean","bandwidth_mean","rolloff_mean","centroid_std"],
#         "train_split": 0.8,
#         "test_split": 0.2
#     }
# )
# 
# 
# 
# # --- 3.2: Train Random Forest Classifier ---
# 
# # TRAIN / VALIDATION
# from sklearn.model_selection import train_test_split
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
# import seaborn as sns, matplotlib.pyplot as plt
# import wandb
# import os, pandas as pd
# 
# # 1Ô∏è‚É£ Split the processed feature dataset
# X_train, X_test, y_train, y_test = train_test_split(
#     X, y, test_size=0.2, random_state=42, stratify=y
# )
# 
# 
# 
# # 3Ô∏è‚É£ Train the Random Forest model
# rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
# rf.fit(X_train, y_train)
# 
# # 4Ô∏è‚É£ Evaluate performance
# y_pred = rf.predict(X_test)
# acc = accuracy_score(y_test, y_pred)
# macro_f1 = f1_score(y_test, y_pred, average="macro")
# 
# print(f"Accuracy: {acc:.3f}")
# print(f"Macro F1: {macro_f1:.3f}")
# print(classification_report(y_test, y_pred))
# 
# 
# # 5Ô∏è‚É£ Confusion Matrix
# plt.figure(figsize=(8,6))
# sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Greens")
# plt.title("Confusion Matrix ‚Äî Random Forest (Processed Audio Features)")
# plt.xlabel("Predicted"); plt.ylabel("True")
# plt.tight_layout()
# plt.show()
# 
# # 6Ô∏è‚É£ Save results for your presentation/report
# os.makedirs("reports", exist_ok=True)
# rep = classification_report(y_test, y_pred, output_dict=True)
# pd.DataFrame(rep).T.to_csv("reports/random_forest_report.csv", index=False)
# plt.figure(figsize=(8,6))
# sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Greens")
# plt.title("Confusion Matrix ‚Äî Random Forest Baseline")
# plt.xlabel("Predicted"); plt.ylabel("True")
# plt.tight_layout()
# plt.savefig("reports/confusion_matrix_rf.png", dpi=150)
# print("‚úÖ Saved: reports/random_forest_report.csv")
# print("‚úÖ Saved: reports/confusion_matrix_rf.png")
# 
# 
# 
# wandb.log({
#     "accuracy": acc,
#     "macro_f1": macro_f1,
#     "confusion_matrix": wandb.Image("reports/confusion_matrix_rf.png")
# })
# 
# wandb.finish()  # ‚úÖ Close AFTER logging
#



from time import perf_counter
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

grid = [50, 100, 200, 400]   # 4 quick experiments
timings = []
for n in grid:
    t0 = perf_counter()
    rf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)
    rf.fit(X_train, y_train)
    y_pred = rf.predict(X_test)
    dt = perf_counter() - t0
    acc = accuracy_score(y_test, y_pred)
    print(f"{n} trees ‚Üí acc={acc:.3f}, time={dt:.1f}s")
    timings.append(dt)

print(f"Avg time per run: {sum(timings)/len(timings):.1f}s")

import os
os.makedirs("reports", exist_ok=True)

# @title Save Baseline Results for Presentation and Sharing
import pandas as pd, seaborn as sns, matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import wandb

# 1Ô∏è‚É£ Save numeric classification report
rep = classification_report(y_test, y_pred, output_dict=True)
pd.DataFrame(rep).T.to_csv("reports/random_forest_report.csv", index=False)
print("‚úÖ Saved: reports/random_forest_report.csv")

# 2Ô∏è‚É£ Save confusion matrix as image
plt.figure(figsize=(8,6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Greens")
plt.title("Confusion Matrix ‚Äî Random Forest Baseline")
plt.xlabel("Predicted"); plt.ylabel("True")
plt.tight_layout()
plt.savefig("reports/confusion_matrix_rf.png", dpi=150)
print("‚úÖ Saved: reports/confusion_matrix_rf.png")



# 3Ô∏è‚É£ (Optional) Check file sizes for report section
!du -h reports/random_forest_report.csv
!du -h reports/confusion_matrix_rf.png



# @title 3.3: Save Features for Team Use
os.makedirs("reports", exist_ok=True)
qdf.to_csv("reports/frog_audio_quality_features.csv", index=False)
print("üíæ Saved reports/frog_audio_quality_features.csv")

"""The `supabase` library has been installed. Now let's fix the environment variable loading and rerun the data fetching step."""

# Step 1: Import required libraries and load environment variables
# Make sure you have added SUPABASE_URL and SUPABASE_KEY to Colab secrets.
import os
# from dotenv import load_dotenv # No longer needed when using Colab secrets
import pandas as pd
from supabase import create_client, Client
from google.colab import userdata # Import userdata to access secrets

# Load environment variables
# load_dotenv() # No longer needed when using Colab secrets

# Get Supabase credentials from Colab secrets
url = userdata.get("SUPABASE_URL")
key = userdata.get("SUPABASE_KEY")


if not url or not key:
    raise ValueError("Please set SUPABASE_URL and SUPABASE_KEY in Colab secrets.")

# Initialize the Supabase client
supabase: Client = create_client(url, key)

# Step 2: Query the audio_files table from Supabase
# This pulls all metadata for the audio files into a pandas DataFrame.
res = supabase.table("audio_files").select(
    "id,bucket_id,object_name,content_type,size_bytes,created_at,top_level_folder,second_level_folder,species"
).execute()

# Convert to DataFrame
df = pd.DataFrame(res.data)
print(df.head())

# Step 3: Quick inspection of object names
# This helps you understand the folder structure and naming conventions for your audio files.
for obj_name in df['object_name']:
    print(obj_name)

# Step 4: Data Cleaning - Remove unwanted audio instances
# For model training, we want to exclude audio files that contain human speech.
# These are labeled in the 'frog_human' folder, and only occur in the 'macaulay_library' top-level folder.
# This step drops all such instances from the DataFrame.
mask = ~((df['object_name'].str.contains('frog_human')) & (df['top_level_folder'] == 'macaulay_library'))
df_clean = df[mask].reset_index(drop=True)
print(f"Original shape: {df.shape}")
print(f"Cleaned shape: {df_clean.shape}")
print(df_clean.head())

# Step 5: Basic EDA (Exploratory Data Analysis)
# This gives an overview of the cleaned DataFrame and helps spot issues before further processing.
print('Shape:', df_clean.shape)
print('Columns:', df_clean.columns.tolist())
print('Missing values per column:')
print(df_clean.isnull().sum())
print('Data types:')
print(df_clean.dtypes)
print('Summary statistics:')
print(df_clean.describe(include='all'))

# Step 6: Breakdown of instances per species
# This helps you understand class balance and identify rare species.
species_counts = df_clean['species'].value_counts()
print("Species counts:")
print(species_counts)

# Commented out IPython magic to ensure Python compatibility.
# Step 7: Install librosa for audio analysis
# This library is used for feature extraction and visualization of audio files.
# %pip install librosa

"""# Exploratory Data Analysis (EDA) of Frog Audio Files
Let's explore the dataset to understand its structure and key statistics.
"""

# Step 8: Download and analyze a sample audio file
# This demonstrates how to fetch an audio file from Supabase, load it, and visualize its properties.
import librosa
import librosa.display
import matplotlib.pyplot as plt
import io
import requests
import tempfile
import os
from IPython.display import Audio
import numpy as np

# Select the first audio file from the cleaned DataFrame
sample_row = df_clean.iloc[0]
bucket_id = sample_row['bucket_id']
object_name = sample_row['object_name']
print('Analyzing:', object_name)

# Download the audio file from Supabase storage
def download_audio(supabase, bucket_id, object_name):
    public_url_response = supabase.storage.from_(bucket_id).get_public_url(object_name)
    # Handle both dict and string return types
    if isinstance(public_url_response, dict):
        public_url = public_url_response.get('publicUrl')
    else:
        public_url = public_url_response
    if not public_url:
        raise Exception('Could not get public URL for file')
    response = requests.get(public_url)
    response.raise_for_status()
    return response.content

audio_bytes = download_audio(supabase, bucket_id, object_name)

# Save to a temporary file
with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
    tmp_file.write(audio_bytes)
    tmp_path = tmp_file.name

# Load audio with librosa
y, sr = librosa.load(tmp_path, sr=None)
print(f'Sample rate: {sr}')
print(f'Duration (seconds): {librosa.get_duration(y=y, sr=sr):.2f}')

# Display audio player
Audio(tmp_path)

# Plot waveform
plt.figure(figsize=(12, 4))
librosa.display.waveshow(y, sr=sr)
plt.title('Waveform')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.show()

# Plot spectrogram
D = librosa.amplitude_to_db(librosa.stft(y), ref=np.max)
plt.figure(figsize=(12, 4))
librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')
plt.title('Spectrogram')
plt.colorbar(format='%+2.0f dB')
plt.tight_layout()
plt.show()

# Clean up temporary file
os.remove(tmp_path)